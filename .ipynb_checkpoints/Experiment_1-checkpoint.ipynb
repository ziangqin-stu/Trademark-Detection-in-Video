{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting...\n",
      "    0.0s video detected.\n",
      "    10.0s video detected.\n",
      "    20.0s video detected.\n",
      "    30.0s video detected.\n",
      "    40.0s video detected.\n",
      "    50.0s video detected.\n",
      "    60.0s video detected.\n",
      "    70.0s video detected.\n",
      "    80.0s video detected.\n",
      "    90.0s video detected.\n",
      "    100.0s video detected.\n",
      "    110.0s video detected.\n",
      "    120.0s video detected.\n",
      "    130.0s video detected.\n",
      "    140.0s video detected.\n",
      "    150.0s video detected.\n",
      "    160.0s video detected.\n",
      "    170.0s video detected.\n",
      "    180.0s video detected.\n",
      "    190.0s video detected.\n",
      "    200.0s video detected.\n",
      "    210.0s video detected.\n",
      "    220.0s video detected.\n",
      "    230.0s video detected.\n",
      "    240.0s video detected.\n",
      "    250.0s video detected.\n",
      "    260.0s video detected.\n",
      "    270.0s video detected.\n",
      "    280.0s video detected.\n",
      "    290.0s video detected.\n",
      "Detection finished in 735.3810243001095 seconds.\n",
      "22 [[0, 1918], [0, 1918], [1, 5410], [1, 5410], [1, 5410], [1, 5410], [1, 5410], [1, 5410], [1, 5410], [1, 5410], [1, 5410], [1, 5410], [1, 5410], [1, 5410], [1, 5410], [1, 5410], [1, 5410], [1, 5410], [1, 5410], [1, 5410], [1, 5410], [1, 5410]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "\n",
    "class DetectIcon:\n",
    "    \n",
    "    def __init__(self, videoPath, iconPathSet):\n",
    "        self.width = 480\n",
    "        self.height = 270\n",
    "        self.frameOffset = 0\n",
    "        self.frameLength = 388800\n",
    "        self.frameSize = 129600\n",
    "        self.frameRate = 30\n",
    "        \n",
    "        \n",
    "        self.iconPathSet = iconPathSet\n",
    "        self.iconSet = [ np.array(Image.open(iconPath)) for iconPath in self.iconPathSet ]\n",
    "        ## self.iconSet = [ cv2.cvtColor(np.array(Image.open(iconPath)), cv2.COLOR_BGR2GRAY) for iconPath in self.iconPathSet ]\n",
    "        # Pre-process on brand-icons\n",
    "        self.iconInfoSet = []\n",
    "        self.orb = cv2.ORB_create() \n",
    "        for icon in self.iconSet:\n",
    "            kpi, desi = self.orb.detectAndCompute(icon,None)\n",
    "            self.iconInfoSet.append([kpi, desi])\n",
    "        \n",
    "        # Laod the .rgb video file into Memory\n",
    "        self.videoPath = videoPath\n",
    "        self.file = open(self.videoPath, 'rb')    ## consider the opne-mode!\n",
    "        \n",
    "        # store result\n",
    "        self.ans = []\n",
    "        self.imgsShow = []\n",
    "    \n",
    "    \n",
    "    def img_compare(self):\n",
    "        for i in range(len(self.imgsShow)):\n",
    "            cv2.imshow(\"img_cmp_{}\".format(i), self.imgsShow[i])\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "    def output_regularize(self, slack=8):\n",
    "        outPutIndexSet = []\n",
    "        ansNumber = len(self.ans)\n",
    "        if ansNumber < 1:\n",
    "            return None\n",
    "        for i in range(ansNumber):\n",
    "            op_i = self.ans[i]\n",
    "            if i+1 < ansNumber:\n",
    "                for j in range(i, ansNumber):\n",
    "                    if self.ans[j][0] != op_i[0] or self.ans[j][1]-op_i[1] > slack*self.frameRate:\n",
    "                        outPutIndexSet.append(j)\n",
    "                        break\n",
    "            else:\n",
    "                if len(outPutIndexSet)>0 and op_i[0] != self.ans[outPutIndexSet[-1]][0]:\n",
    "                    outPutIndexSet.append(i)\n",
    "                elif len(outPutIndexSet)<1:\n",
    "                    outPutIndexSet.append(i)\n",
    "        outPutIndexSet = list(set(outPutIndexSet))\n",
    "        self.ans = [ self.ans[outPutIndex] for outPutIndex in outPutIndexSet ]\n",
    "        self.imgsShow = [ self.imgsShow[outPutIndex] for outPutIndex in outPutIndexSet ]\n",
    "                \n",
    "    \n",
    "    def cut_copy_image(self, img, size, corner=[0,0]):\n",
    "        # initialization\n",
    "        width = 480\n",
    "        height = 270\n",
    "        cWidth = size[0]\n",
    "        cHeight = size[1]\n",
    "\n",
    "        frameSize = width*height\n",
    "        framOffsetWidth = corner[0]\n",
    "        framOffsetHeight = corner[1]\n",
    "        lineSkip = width-cWidth\n",
    "\n",
    "\n",
    "        cut = np.full((cHeight,cWidth,3), 0, np.uint8)\n",
    "\n",
    "        # cut-copy image\n",
    "        ind = framOffsetWidth + framOffsetHeight*width\n",
    "        for y in range(cHeight):\n",
    "            for x in range(cWidth):\n",
    "                cut[y][x] = [img[ind], img[ind + frameSize], img[ind + frameSize*2]]\n",
    "                ind += 1\n",
    "            ind += lineSkip\n",
    "        return cut\n",
    "    \n",
    "    \n",
    "    def detect_one_frame(self, frameNumber, iconIndex, threshHold=10, passLine=0.75, imshow=True, corner=[0,0], zoomProp=1/6):\n",
    "        isFound = False\n",
    "        \n",
    "        # initialization\n",
    "        pWidth = int(self.width * (1-2*zoomProp))\n",
    "        pHeight = int(self.height * (1-2*zoomProp))\n",
    "        frameArr = np.full((pHeight, pWidth, 3), 0, np.uint8)\n",
    "        \n",
    "        # locate & laod .rgb frame\n",
    "        position = self.frameLength * frameNumber\n",
    "        self.file.seek(position, 0)\n",
    "        frameByte = self.file.read(self.frameLength)\n",
    "\n",
    "        # transfer .rgb frame to ndarray\n",
    "        frameArr = self.cut_copy_image(frameByte, [pWidth, pHeight], corner)\n",
    "        \n",
    "\n",
    "        # get key-point info of Detecting-Area\n",
    "        alignFrameArr = cv2.resize(frameArr, (480, 270), interpolation=cv2.INTER_LANCZOS4)\n",
    "        ## alignFrameArr = cv2.cvtColor(alignFrameArr, cv2.COLOR_BGR2GRAY)\n",
    "        kpf, desf = self.orb.detectAndCompute(alignFrameArr,None)\n",
    "\n",
    "        # compare with brand-icon info\n",
    "        bf = cv2.BFMatcher()\n",
    "        matches = bf.knnMatch(self.iconInfoSet[iconIndex][1], desf, k=2)\n",
    "        \n",
    "        # collect good matches\n",
    "        good = []\n",
    "        imgMatchNumber = []\n",
    "        for m,n in matches:\n",
    "            if m.distance < passLine*n.distance:\n",
    "                good.append([m])\n",
    "                if kpf[m.trainIdx].pt not in imgMatchNumber:\n",
    "                    imgMatchNumber.append(kpf[m.trainIdx].pt)\n",
    "        \n",
    "        \n",
    "        # Continue zoom-in \n",
    "        if len(good) >= threshHold:\n",
    "            isFound = True\n",
    "            if imshow:\n",
    "                print(\"  |--> Zoom-In Detection:\")\n",
    "                matchCompImg = cv2.drawMatchesKnn(self.iconSet[iconIndex], self.iconInfoSet[iconIndex][0], alignFrameArr, kpf, good, None, flags=2)  ## what is 'flags'?\n",
    "                plt.figure(\"matchCompImg\"); plt.imshow(matchCompImg); plt.axis('off'); plt.show()\n",
    "        \n",
    "        # return result\n",
    "        ## if isFound:\n",
    "            ## print(\"        | Pass!, frame={}, icon_id={}, #good={} |\".format(frameNumber, iconIndex, len(good)))\n",
    "        ## else:\n",
    "            ## print(\"        | Not Pass!, frame={}, icon_id={}, #good={} |\".format(frameNumber, iconIndex, len(good)))\n",
    "        return isFound\n",
    "    \n",
    "    \n",
    "    def detect_zoom_in(self, img, iconIndex, threshHold=10, passLine=0.75, imshow=True, corner=[0,0], zoomProp=1/6):\n",
    "        isFound = False\n",
    "        \n",
    "        # initialization\n",
    "        pWidth = int(self.width * (1-2*zoomProp))\n",
    "        pHeight = int(self.height * (1-2*zoomProp))\n",
    "\n",
    "        # regulize corner\n",
    "        corner[0] = min( int(corner[0]), int(self.width*2*zoomProp) ); corner[0] = max(corner[0], 0)\n",
    "        corner[1] = min( int(corner[1]), int(self.height*2*zoomProp) ); corner[1] = max(corner[1], 1)\n",
    "        \n",
    "        img = img[ corner[1]:corner[1]+pHeight, corner[0]:corner[0]+pWidth]\n",
    "\n",
    "        # get key-point info of Detecting-Area\n",
    "        img = cv2.resize(img, (480, 270), interpolation=cv2.INTER_LANCZOS4)\n",
    "        kpf, desf = self.orb.detectAndCompute(img,None)\n",
    "        if len(kpf)<1 or len(desf)<1:\n",
    "            return [False, [-1, -1], img, None, None]\n",
    "        \n",
    "\n",
    "        # compare with brand-icon info\n",
    "        bf = cv2.BFMatcher()\n",
    "        matches = bf.knnMatch(self.iconInfoSet[iconIndex][1], desf, k=2)\n",
    "        \n",
    "        # collect good matches\n",
    "        good = []\n",
    "        imgMatchNumber = []\n",
    "        center = np.array([0, 0])\n",
    "        for m,n in matches:\n",
    "            if m.distance < passLine*n.distance:\n",
    "                good.append([m])\n",
    "                if kpf[m.trainIdx].pt not in imgMatchNumber:\n",
    "                    imgMatchNumber.append(kpf[m.trainIdx].pt)\n",
    "                center = np.array([center[0]+kpf[m.trainIdx].pt[0], center[1]+kpf[m.trainIdx].pt[1]])\n",
    "        if len(good):\n",
    "            center = center / len(good)\n",
    "        \n",
    "        # Continue zoom-in \n",
    "        if len(good) >= threshHold and len(imgMatchNumber) > 0.5*len(good): isFound = True\n",
    "\n",
    "        # return result\n",
    "        if isFound:\n",
    "            ## print(\"        | Pass!, icon_id={}, #good={}, len(imgMatchNumber)={} |\".format(iconIndex, len(good), len(imgMatchNumber)) )\n",
    "            if imshow:\n",
    "                print(\"    |--> Zoom-In Detection: #good =\", len(good))\n",
    "                matchCompImg = cv2.drawMatchesKnn(self.iconSet[iconIndex], self.iconInfoSet[iconIndex][0], img, kpf, good, None, flags=2)  ## what is 'flags'?\n",
    "                plt.figure(\"matchCompImg\"); plt.imshow(matchCompImg); plt.axis('off'); plt.show()\n",
    "        ## else:\n",
    "            ## print(\"        | Not Pass!, icon_id={}, #good={}, len(imgMatchNumber) |\".format(iconIndex, len(good), len(imgMatchNumber)) )\n",
    "        return [isFound, center, img, kpf, good]\n",
    "    \n",
    "    \n",
    "    def detect_video_segment(self, threshHold=10, passLine=0.75, start=0, end=10, imshow=True, corner=[0,0], zoomProp=1/6, step=1):\n",
    "        begin = time.clock()\n",
    "        \n",
    "        # Initialization\n",
    "        ans = []\n",
    "        imgsShow = []\n",
    "        frameOffset = start*30\n",
    "        pWidth = int(self.width * (1-2*zoomProp))\n",
    "        pHeight = int(self.height * (1-2*zoomProp))\n",
    "        frameArr = np.full((180,320,3), 0, np.uint8)\n",
    "        position = self.frameLength * frameOffset\n",
    "\n",
    "        # Detect brand-icons in video\n",
    "        print(\"Detecting...\")\n",
    "        while frameOffset <= end*30:\n",
    "            if frameOffset%300 == 0: print(\"    {}s video detected.\".format( (frameOffset-start*30)/30 ) )\n",
    "            \n",
    "            # locate & laod .rgb frame\n",
    "            position = frameOffset * self.frameLength\n",
    "            self.file.seek(position, 0)\n",
    "            frameByte = self.file.read(self.frameLength)\n",
    "\n",
    "            # transfer .rgb frame\n",
    "            frameArr = self.cut_copy_image(frameByte, [pWidth, pHeight], corner)\n",
    "\n",
    "            # get key-point info of current-frame\n",
    "            alignFrameArr = cv2.resize(frameArr, (480, 270), interpolation=cv2.INTER_CUBIC)\n",
    "            kpf, desf = self.orb.detectAndCompute(alignFrameArr,None)\n",
    "\n",
    "            # compare with brand-icon info\n",
    "            bf = cv2.BFMatcher()\n",
    "            for iconInfo in self.iconInfoSet:\n",
    "                iconIndex = self.iconInfoSet.index(iconInfo)\n",
    "                matches = bf.knnMatch(iconInfo[1],desf, k=2)  ## what is 'k'?\n",
    "                # collect good matches & calculate gravity-center\n",
    "                good = []\n",
    "                center = np.array([0, 0])\n",
    "                for m,n in matches:\n",
    "                    if m.distance < passLine*n.distance:\n",
    "                        good.append([m])\n",
    "                        center = np.array([center[0]+kpf[m.trainIdx].pt[0], center[1]+kpf[m.trainIdx].pt[1]])\n",
    "                if len(good):\n",
    "                    center = center / len(good)\n",
    "                \n",
    "                ## Continue Zoom-In:\n",
    "                prop = 1/5\n",
    "                zoomCorner = [ int(center[0]-0.5*self.width*(1-2*prop)), int(center[1]-0.5*self.height*(1-2*prop)) ]\n",
    "                if len(good) >= threshHold:\n",
    "                    ## print(\"B\")\n",
    "                    isFound, center, img1, kpf1, good1 = self.detect_zoom_in(alignFrameArr, iconIndex, threshHold=8, corner=zoomCorner, zoomProp=1/5, imshow=imshow)\n",
    "                    if isFound:\n",
    "                        ## print(\"C\"); \n",
    "                        zoomCorner = [ int(center[0]-0.5*self.width*(1-2*prop)), int(center[1]-0.5*self.height*(1-2*prop)) ]\n",
    "                        isFound, center, img2, kpf2, good2 = self.detect_zoom_in(img1, iconIndex, threshHold=8, corner=zoomCorner, zoomProp=1/5, imshow=imshow)\n",
    "                    if isFound:\n",
    "                        matchCompImg = cv2.drawMatchesKnn(self.iconSet[iconIndex], iconInfo[0], img2, kpf2, good2, None, flags=2)\n",
    "                        imgShow = np.hstack((alignFrameArr, matchCompImg))\n",
    "                        imgsShow.append(imgShow)\n",
    "                        ans.append( [iconIndex, frameOffset] )\n",
    "                        if imshow:\n",
    "                            print(\"Alternative-Frame: \\nframeOffset =\", frameOffset, \"time =\", int(frameOffset/30), \"  icon_ind =\", iconIndex, \"  #good =\", len(good))\n",
    "                            matchCompImg = cv2.drawMatchesKnn(self.iconSet[iconIndex], iconInfo[0], alignFrameArr, kpf, good, None, flags=2)  ## what is 'flags'?\n",
    "                            print(\"A\"); plt.figure(\"matchCompImg\"); plt.imshow(matchCompImg); plt.axis('off'); plt.show()\n",
    "                            \n",
    "            frameOffset += step\n",
    "\n",
    "        # Return\n",
    "        print(\"Detection finished in {} seconds.\".format(time.clock()-begin))\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        self.ans = ans\n",
    "        self.imgsShow = imgsShow\n",
    "        return\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "detect_1 = DetectIcon(videoPath=r'./data/data_test1.rgb', iconPathSet=[r'./data/subway_logo.jpg', r'./data/starbucks_logo.jpg'])\n",
    "## detect_1.detect_one_frame(3262, 0, threshHold=1, corner=[200, 0], zoomProp=11/80)\n",
    "## detect_1.detect_video_segment(threshHold=10, start=70, end=71, step=2)\n",
    "## detect_1.detect_video_segment(threshHold=10, start=180, end=181, step=1)\n",
    "## detect_1.detect_video_segment(threshHold=10, start=0, end=298, step=2, imshow=False)\n",
    "detect_1.output_regularize()\n",
    "print(len(detect_1.ans), detect_1.ans)\n",
    "detect_1.img_compare()\n",
    "\n",
    "\n",
    "## detect_2 = DetectIcon(videoPath=r'./data/data_test2.rgb', iconPathSet=[r'./data/nfl_logo.jpg', r'./data/mcdonalds_logo.jpg'])\n",
    "## ans_2 = detect_2.detect_video_segment(threshHold=6, start=0, end=298, step=2); print(len(ans_), ans_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
