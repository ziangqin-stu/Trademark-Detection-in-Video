{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting...\n",
      "    1.0s video detected.\n",
      "Detection finished in 2.6578454992263687 seconds.\n",
      "Detecting...\n",
      "    0.0s video detected.\n",
      "Detection finished in 4.264242780973291 seconds.\n",
      "len_ans 2 1\n",
      "ans [[[0, 1983], [0, 1995]], [[1, 7049]]]\n",
      "len_ans 1 1\n",
      "ans [[[0, 1995]], [[1, 7049]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "\n",
    "class DetectIcon:\n",
    "    \n",
    "    def __init__(self, videoPath, iconPathSet):\n",
    "        # video info\n",
    "        self.width = 480\n",
    "        self.height = 270\n",
    "        self.frameOffset = 0\n",
    "        self.frameLength = 388800\n",
    "        self.frameSize = 129600\n",
    "        self.frameRate = 30\n",
    "        \n",
    "        # image processing\n",
    "        self.kernel_sharpen = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n",
    "        self.kernel_blur = np.ones((5,5),np.float32)/25\n",
    "        self.interplotation = cv2.INTER_CUBIC  ## INTER_NEAREST INTER_LINEAR INTER_AREA INTER_CUBIC INTER_LANCZOS4\n",
    "        \n",
    "        # icon info\n",
    "        self.iconPathSet = iconPathSet\n",
    "        self.iconSet = [ np.array(Image.open(iconPath)) for iconPath in self.iconPathSet ]\n",
    "        for i in range(10):\n",
    "            self.iconSet[0] = cv2.filter2D(self.iconSet[0], -1, self.kernel_blur)\n",
    "        for i in range(2):\n",
    "            self.iconSet[1] = cv2.filter2D(self.iconSet[1], -1, self.kernel_blur)\n",
    "        ## self.iconSet = [ cv2.cvtColor(np.array(Image.open(iconPath)), cv2.COLOR_BGR2GRAY) for iconPath in self.iconPathSet ]\n",
    "\n",
    "        # Pre-process on brand-icons\n",
    "        self.iconInfoSet = []\n",
    "        self.orb = cv2.ORB_create() \n",
    "        for icon in self.iconSet:\n",
    "            kpi, desi = self.orb.detectAndCompute(icon,None)\n",
    "            self.iconInfoSet.append([kpi, desi])\n",
    "        \n",
    "        # Laod the .rgb video file into Memory\n",
    "        self.videoPath = videoPath\n",
    "        self.file = open(self.videoPath, 'rb')    ## consider the opne-mode!\n",
    "        \n",
    "        # store result\n",
    "        self.ans = [[], []]\n",
    "        self.imgsShow = [[], []]\n",
    "        \n",
    "        \n",
    "     \n",
    "    \n",
    "    def img_compare(self, iconIndexSet=[0,1]):\n",
    "        for iconIndex in iconIndexSet:\n",
    "            for i in range(len(self.imgsShow[iconIndex])):\n",
    "                cv2.imshow(\"img_cmp_{}_{}\".format(iconIndex, i), self.imgsShow[iconIndex][i])\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "    def output_regularize(self, gap=5, minL=2):\n",
    "        outPutIndexSet = [[], []]\n",
    "        for iconIndex in range(2):\n",
    "            if len(self.ans[iconIndex]) == 1:\n",
    "                outPutIndexSet[iconIndex].append(0)\n",
    "                continue\n",
    "            i = 1\n",
    "            isCluster = False\n",
    "            length = 1\n",
    "            while i < len(self.ans[iconIndex]):\n",
    "                if self.ans[iconIndex][i][1]-self.ans[iconIndex][i-1][1] < gap*self.frameRate:\n",
    "                    length += 1\n",
    "                    if length >= minL:\n",
    "                        isCluster = True\n",
    "                elif isCluster:\n",
    "                    outPutIndexSet[iconIndex].append(i)\n",
    "                    length = 1\n",
    "                    isCluster = False\n",
    "                if i == len(self.ans[iconIndex])-1 and isCluster:\n",
    "                    outPutIndexSet[iconIndex].append(i)\n",
    "                i += 1\n",
    "        \n",
    "        for iconIndex in range(2):\n",
    "            self.ans[iconIndex] = [ self.ans[iconIndex][ outPutIndexSet[iconIndex][i] ] for i in range(len(outPutIndexSet[iconIndex])) ]\n",
    "            self.imgsShow[iconIndex] = [ self.imgsShow[iconIndex][ outPutIndexSet[iconIndex][i] ] for i in range(len(outPutIndexSet[iconIndex])) ]\n",
    "\n",
    "            \n",
    "    def cut_copy_image(self, img, size, corner=[0,0]):\n",
    "        # initialization\n",
    "        width = 480\n",
    "        height = 270\n",
    "        cWidth = int(size[0])\n",
    "        cHeight = int(size[1])\n",
    "\n",
    "        frameSize = width*height\n",
    "        framOffsetWidth = corner[0]\n",
    "        framOffsetHeight = corner[1]\n",
    "        lineSkip = width-cWidth\n",
    "\n",
    "\n",
    "        cut = np.full((cHeight,cWidth,3), 0, np.uint8)\n",
    "\n",
    "        # cut-copy image\n",
    "        ind = framOffsetWidth + framOffsetHeight*width\n",
    "        for y in range(cHeight):\n",
    "            for x in range(cWidth):\n",
    "                cut[y][x] = [img[ind], img[ind + frameSize], img[ind + frameSize*2]]\n",
    "                ind += 1\n",
    "            ind += lineSkip\n",
    "        return cut\n",
    "    \n",
    "    \n",
    "    def detect_one_frame(self, frameNumber, iconIndex, threshHold=10, passLine=0.75, imshow=True, corner=[0,0], zoomProp=1/6):\n",
    "        isFound = False\n",
    "        \n",
    "        # initialization\n",
    "        pWidth = int(self.width * (1-2*zoomProp))\n",
    "        pHeight = int(self.height * (1-2*zoomProp))\n",
    "        frameArr = np.full((pHeight, pWidth, 3), 0, np.uint8)\n",
    "        \n",
    "        # locate & laod .rgb frame\n",
    "        position = self.frameLength * frameNumber\n",
    "        self.file.seek(position, 0)\n",
    "        frameByte = self.file.read(self.frameLength)\n",
    "\n",
    "        # transfer .rgb frame to ndarray\n",
    "        frameArr = self.cut_copy_image(frameByte, [pWidth, pHeight], corner)\n",
    "        \n",
    "\n",
    "        # get key-point info of Detecting-Area\n",
    "        alignFrameArr = cv2.resize(frameArr, (480, 270), interpolation=self.interplotation)\n",
    "        ## alignFrameArr = cv2.filter2D(alignFrameArr, -1, kernel=self.kernel)\n",
    "        \n",
    "        kpf, desf = self.orb.detectAndCompute(alignFrameArr,None)\n",
    "\n",
    "        # compare with brand-icon info\n",
    "        bf = cv2.BFMatcher()\n",
    "        matches = bf.knnMatch(self.iconInfoSet[iconIndex][1], desf, k=2)\n",
    "        \n",
    "        # collect good matches\n",
    "        good = []\n",
    "        imgMatchNumber = []\n",
    "        for m,n in matches:\n",
    "            if m.distance < passLine*n.distance:\n",
    "                good.append([m])\n",
    "                if kpf[m.trainIdx].pt not in imgMatchNumber:\n",
    "                    imgMatchNumber.append(kpf[m.trainIdx].pt)\n",
    "        \n",
    "        \n",
    "        # Continue zoom-in \n",
    "        if len(good) >= threshHold:\n",
    "            isFound = True\n",
    "            if imshow:\n",
    "                ## print(\"  |--> Zoom-In Detection:\")\n",
    "                matchCompImg = cv2.drawMatchesKnn(self.iconSet[iconIndex], self.iconInfoSet[iconIndex][0], alignFrameArr, kpf, good, None, flags=2)  ## what is 'flags'?\n",
    "                plt.figure(\"matchCompImg\"); plt.imshow(matchCompImg); plt.axis('off'); plt.show()\n",
    "        \n",
    "        # return result\n",
    "        ## if isFound:\n",
    "           ## print(\"        | Pass!, frame={}, icon_id={}, #good={} |\".format(frameNumber, iconIndex, len(good)))\n",
    "        ## else:\n",
    "           ## print(\"        | Not Pass!, frame={}, icon_id={}, #good={} |\".format(frameNumber, iconIndex, len(good)))\n",
    "        ## return isFound\n",
    "    \n",
    "    \n",
    "    def detect_zoom_in(self, img, iconIndex, threshHold=10, passLine=0.75, imshow=True, corner=[0,0], zoomProp=1/6):\n",
    "        isFound = False\n",
    "        \n",
    "        # initialization\n",
    "        pWidth = int(self.width * (1-2*zoomProp))\n",
    "        pHeight = int(self.height * (1-2*zoomProp))\n",
    "\n",
    "        # regulize corner\n",
    "        corner[0] = min( int(corner[0]), int(self.width*2*zoomProp) ); corner[0] = max(corner[0], 0)\n",
    "        corner[1] = min( int(corner[1]), int(self.height*2*zoomProp) ); corner[1] = max(corner[1], 1)\n",
    "        \n",
    "        img = img[ corner[1]:corner[1]+pHeight, corner[0]:corner[0]+pWidth]\n",
    "\n",
    "        # get key-point info of Detecting-Area\n",
    "        img = cv2.resize(img, (480, 270), interpolation=self.interplotation)\n",
    "        ## img = cv2.filter2D(img, -1, kernel=self.kernel)\n",
    "        kpf, desf = self.orb.detectAndCompute(img,None)\n",
    "        if len(kpf)<1 or len(desf)<1:\n",
    "            return [False, [-1, -1], img, None, None]\n",
    "        \n",
    "\n",
    "        # compare with brand-icon info\n",
    "        bf = cv2.BFMatcher()\n",
    "        matches = bf.knnMatch(self.iconInfoSet[iconIndex][1], desf, k=2)\n",
    "        \n",
    "        # collect good matches\n",
    "        good = []\n",
    "        imgMatchNumber = []\n",
    "        center = np.array([0, 0])\n",
    "        for i, pair in enumerate(matches):\n",
    "            try:\n",
    "                m, n = pair\n",
    "                if m.distance < passLine*n.distance:\n",
    "                    good.append([m])\n",
    "                    if kpf[m.trainIdx].pt not in imgMatchNumber:\n",
    "                        imgMatchNumber.append(kpf[m.trainIdx].pt)\n",
    "                    center = np.array([center[0]+kpf[m.trainIdx].pt[0], center[1]+kpf[m.trainIdx].pt[1]])\n",
    "            except ValueError:\n",
    "                pass\n",
    "        if len(good):\n",
    "            center = center / len(good)\n",
    "        \n",
    "        # Continue zoom-in \n",
    "        if len(good) >= threshHold and len(imgMatchNumber) > 0.6*len(good): isFound = True\n",
    "\n",
    "        # return result\n",
    "        if isFound:\n",
    "            ## print(\"        | Pass!, icon_id={}, #good={}, len(imgMatchNumber)={} |\".format(iconIndex, len(good), len(imgMatchNumber)) )\n",
    "            if imshow:\n",
    "                print(\"    |--> Zoom-In Detection: #good =\", len(good))\n",
    "                matchCompImg = cv2.drawMatchesKnn(self.iconSet[iconIndex], self.iconInfoSet[iconIndex][0], img, kpf, good, None, flags=2)  ## what is 'flags'?\n",
    "                plt.figure(\"matchCompImg\"); plt.imshow(matchCompImg); plt.axis('off'); plt.show()\n",
    "        ## else:\n",
    "            ## print(\"        | Not Pass!, icon_id={}, #good={}, len(imgMatchNumber) |\".format(iconIndex, len(good), len(imgMatchNumber)) )\n",
    "        return [isFound, center, img, kpf, good]\n",
    "    \n",
    "    \n",
    "    def detect_video_segment(self, iconIndexSet=[0,1], threshHold=[10,8,8,8,8], passLine=0.75, start=0, end=10, imshow=True, corner=[0,0], zoomProp=1/6, step=1):\n",
    "        begin = time.clock()\n",
    "        \n",
    "        # Initialization\n",
    "        ans = []\n",
    "        imgsShow = []\n",
    "        frameOffset = start*30\n",
    "        pWidth = int(self.width * (1-2*zoomProp))\n",
    "        pHeight = int(self.height * (1-2*zoomProp))\n",
    "        frameArr = np.full((180,320,3), 0, np.uint8)\n",
    "        position = self.frameLength * frameOffset\n",
    "\n",
    "        # Detect brand-icons in video\n",
    "        print(\"Detecting...\")\n",
    "        while frameOffset <= end*30:\n",
    "            if frameOffset%90 == 0: print(\"    {}s video detected.\".format( (frameOffset-start*30)/30 ) )\n",
    "            \n",
    "            # locate & laod .rgb frame\n",
    "            position = frameOffset * self.frameLength\n",
    "            self.file.seek(position, 0)\n",
    "            frameByte = self.file.read(self.frameLength)\n",
    "\n",
    "            # transfer .rgb frame\n",
    "            frameArr = self.cut_copy_image(frameByte, [pWidth, pHeight], corner)\n",
    "\n",
    "            # get key-point info of current-frame\n",
    "            alignFrameArr = cv2.resize(frameArr, (480, 270), interpolation=self.interplotation)\n",
    "            ## alignFrameArr = cv2.filter2D(alignFrameArr, -1, kernel=self.kernel)\n",
    "            kpf, desf = self.orb.detectAndCompute(alignFrameArr,None)\n",
    "            if len(kpf)<1 or len(desf)<1:\n",
    "                frameOffset += step\n",
    "                continue\n",
    "\n",
    "            # compare with brand-icon info\n",
    "            bf = cv2.BFMatcher()\n",
    "            for iconIndex in iconIndexSet:\n",
    "                iconInfo = self.iconInfoSet[iconIndex]\n",
    "                matches = bf.knnMatch(iconInfo[1],desf, k=2)  ## what is 'k'?\n",
    "                # collect good matches & calculate gravity-center\n",
    "                good = []\n",
    "                center = np.array([0, 0])\n",
    "                for m,n in matches:\n",
    "                    if m.distance < passLine*n.distance:\n",
    "                        good.append([m])\n",
    "                        center = np.array([center[0]+kpf[m.trainIdx].pt[0], center[1]+kpf[m.trainIdx].pt[1]])\n",
    "                if len(good):\n",
    "                    center = center / len(good)\n",
    "                \n",
    "                ## Continue Zoom-In:\n",
    "                prop = 1/5\n",
    "                zoomCorner = [ int(center[0]-0.5*self.width*(1-2*prop)), int(center[1]-0.5*self.height*(1-2*prop)) ]\n",
    "                if len(good) >= threshHold[0]:\n",
    "                    ## print(\"      B\")\n",
    "                    isFound, center, img1, kpf1, good1 = self.detect_zoom_in(alignFrameArr, iconIndex, threshHold=threshHold[1], corner=zoomCorner, passLine=passLine, zoomProp=1/5, imshow=imshow)\n",
    "                    if isFound:\n",
    "                        ## print(\"      C\"); \n",
    "                        zoomCorner = [ int(center[0]-0.5*self.width*(1-2*prop)), int(center[1]-0.5*self.height*(1-2*prop)) ]\n",
    "                        isFound, center, img2, kpf2, good2 = self.detect_zoom_in(img1, iconIndex, threshHold=threshHold[2], corner=zoomCorner, passLine=passLine, zoomProp=1/5, imshow=imshow)\n",
    "                    if isFound:\n",
    "                        ## print(\"      D\"); \n",
    "                        zoomCorner = [ int(center[0]-0.5*self.width*(1-2*prop)), int(center[1]-0.5*self.height*(1-2*prop)) ]\n",
    "                        isFound, center, img3, kpf3, good3 = self.detect_zoom_in(img2, iconIndex, threshHold=threshHold[3], corner=zoomCorner, passLine=passLine, zoomProp=1/5, imshow=imshow)\n",
    "                    if isFound:\n",
    "                        ## print(\"      E\"); \n",
    "                        zoomCorner = [ int(center[0]-0.5*self.width*(1-2*prop)), int(center[1]-0.5*self.height*(1-2*prop)) ]\n",
    "                        isFound, center, img4, kpf4, good4 = self.detect_zoom_in(img3, iconIndex, threshHold=threshHold[4], corner=zoomCorner, passLine=passLine, zoomProp=1/5, imshow=imshow)\n",
    "                    if isFound:\n",
    "                        matchCompImg = cv2.drawMatchesKnn(self.iconSet[iconIndex], iconInfo[0], img4, kpf4, good4, None, flags=2)\n",
    "                        imgShow = np.hstack((alignFrameArr, matchCompImg))\n",
    "                        self.imgsShow[iconIndex].append(imgShow)\n",
    "                        self.ans[iconIndex].append( [iconIndex, frameOffset] )\n",
    "                        if imshow:\n",
    "                            ## print(\"Alternative-Frame: \\nframeOffset =\", frameOffset, \"time =\", int(frameOffset/30), \"  icon_ind =\", iconIndex, \"  #good =\", len(good))\n",
    "                            matchCompImg = cv2.drawMatchesKnn(self.iconSet[iconIndex], iconInfo[0], alignFrameArr, kpf, good, None, flags=2)  ## what is 'flags'?\n",
    "                            ## print(\"      A\"); \n",
    "                            plt.figure(\"matchCompImg\"); plt.imshow(matchCompImg); plt.axis('off'); plt.show()\n",
    "                            \n",
    "            frameOffset += step\n",
    "\n",
    "        # Return\n",
    "        print(\"Detection finished in {} seconds.\".format(time.clock()-begin))\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        return [self.ans, self.imgsShow]\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "detect_3 = DetectIcon(videoPath=r'./data/data_test3.rgb', iconPathSet=[r'./data/ae_logo.jpg', r'./data/hrc_logo.jpg'])  ## r'./data/hrc_logo.jpg'\n",
    "## detect_3.detect_one_frame(2400, 0, threshHold=1, corner=[0,0], zoomProp=1/6)\n",
    "detect_3.detect_video_segment(iconIndexSet=[0], threshHold=[2,1,2,5,5], passLine=0.75, start=65, end=67, step=3, zoomProp=1/6, imshow=False)\n",
    "detect_3.detect_video_segment(iconIndexSet=[1], threshHold=[2,2,2,3,3], passLine=0.65, start=234, end=235, step=1, zoomProp=1/6, imshow=False)\n",
    "print(\"len_ans\", len(detect_3.ans[0]), len(detect_3.ans[1])); print(\"ans\", detect_3.ans)\n",
    "detect_3.output_regularize()\n",
    "print(\"len_ans\", len(detect_3.ans[0]), len(detect_3.ans[1])); print(\"ans\", detect_3.ans)\n",
    "detect_3.img_compare()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
